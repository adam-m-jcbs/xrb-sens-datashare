{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base Python imports\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get the location of raw_pickles, assuming you run this notebook in xrb-sens-datashare/raw_pickles\n",
    "import os\n",
    "cur_data_root = os.getcwd()\n",
    "print('Using raw_pickles data root:\\n   {}'.format(cur_data_root))\n",
    "#'/home/ajacobs/Reporoot/xrb-sens-datashare/raw_pickles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derive analysis and kepler locations from root\n",
    "package_root = '{}/../analysis_packages'.format(cur_data_root)\n",
    "kepler_package_root = '{}/../kepler_python_packages'.format(cur_data_root)\n",
    "\n",
    "#Insert kepler python packages into the python path\n",
    "sys.path.insert(0, '{}/python_scripts'.format(kepler_package_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide analysis, data abstraction, and reduction modules as well as modules\n",
    "#that understand Kepler's data formats\n",
    "#NOTE: This is very hacky and brittle. Should be improved in next development iteration.\n",
    "import re\n",
    "from pickle import dump, load\n",
    "from glob import glob\n",
    "from os.path import basename, join\n",
    "from random import sample\n",
    "from scipy.constants import physical_constants\n",
    "\n",
    "#import grid_setup\n",
    "#from model_analysis import ModelAnalysis\n",
    "from lcdata import LCData\n",
    "from kepdata import KepData\n",
    "from kepdump import KepDump\n",
    "from isoplot import IsoPlot\n",
    "from nucplot import IsoPlot as NucPlot\n",
    "import bdat\n",
    "import ionmap\n",
    "from isotope import el2z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dependencies provided, reading up to the entire raw data set is as easy as\n",
    "manipulating a nested Python dictionary full of performant numpy objects as\n",
    "well as self-documenting labels/descriptions.\n",
    "\n",
    "Below, we explore the dictionary at a high level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is a reference example of leading in the pickle, doing some checks, and\n",
    "#highlighting some of the detailed data available.\n",
    "\n",
    "#Load in the raw data\n",
    "#with open('4u1820ZJ_100x_grid_data.Nov18.pk', 'rb') as f:\n",
    "with open('gs1826_10x_grid_data.Nov5.pk', 'rb') as f:\n",
    "    grid_data = load(f)\n",
    "\n",
    "gd = grid_data\n",
    "\n",
    "#Do a basic check of the data\n",
    "#summarize the grid properties\n",
    "print(\"Grid label:       {}\".format(gd['grid_label']))\n",
    "print(\"Grid description: {}\".format(gd['grid_desc']))\n",
    "print(\"X:      {}\".format(gd['x']))\n",
    "print(\"Z(n14): {}\".format(gd['z']))\n",
    "print(\"Q_b:    {} MeV / u\".format(gd['qb']))\n",
    "print(\"Eddington fraction: {}\".format(gd['eddf']))\n",
    "print(\"xi: {}\".format(gd['xi']))\n",
    "print(\"Accretion Lum: {} erg / s\".format(gd['acc_lum']))\n",
    "print(\"Accretion Rate: {} M_sol / yr\".format(gd['acc_rate']))\n",
    "print(\"surface gravity, g: {} cm / s^2\".format(gd['gee']))\n",
    "print(\"# of variations (may be off by 1, see source): {}\".format(len(gd['vary_list'])-1)) #-1 because we currently put fake variation in first to gen the baseline\n",
    "print(\"# of models: {}\".format(len(gd['model_data'])))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data on the entire grid is at the first level of the nested dictionary.  Specifically, they are:\n",
    "    \n",
    "```\n",
    "grid_data{\n",
    "    'grid_label': simple string labeling this grid of data,\n",
    "    'grid_desc':  short human-readable description of the grid,\n",
    "    'x':          hydrogen mass fraction of the baseline bursting model,\n",
    "    'z':          metalicity of baseline model,\n",
    "    'qb':         base heating in MeV/u (has dependence on accretion),\n",
    "    'eddf':       Eddington fraction of the luminosity,\n",
    "    'xi':         geometric factor that's not used, just set to 1 for this study,\n",
    "    'acc_lum':    accretion luminosity, the luminosity generated at base by accretion,\n",
    "    'acc_rate':   accretion rate,\n",
    "    'gee':        local gravity g,\n",
    "    'vary_list':  a list of tuples descripting this grid's variations as ('Abc', X) \n",
    "                  where Abc references reaction form A(b,c)D and X is the factor that reaction was scaled by,\n",
    "    'model_data': the bulk of the model data is here, we will dive into it later,\n",
    "    'models_to_debug': a list of models experiencing issues,\n",
    "}\n",
    "```\n",
    "Concrete examples can be seen in the next code cell  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in gd.keys():\n",
    "    if key == 'model_data':\n",
    "        continue\n",
    "    print('{} --> {}'.format(key, gd[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detailed data for each model can be found in `grid_data['model_data']` and is keyed based on the model's reaction variations.\n",
    "\n",
    "For example, `grid_data['model_data']['dag0.1']` contains data for the baseline model (GS1826 in this case) with a variation of the d(alpha, gamma) reaction down by a factor of 10 (hence 0.1).\n",
    "\n",
    "`grid_data['model_data']['o15ag10.0']` contains data for O15 (alpha, gamma) being varied up by a factor of 10.\n",
    "\n",
    "Model labels generally follow this form.  Below, we print out a list of all model labels.  Note that on occasion special labels are made, like 'base'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count = len(gd['model_data'])\n",
    "print('There are a total of {} models in model_data\\n'.format(model_count))\n",
    "labels = (label for label in gd['model_data'].keys())\n",
    "\n",
    "for label in labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model has associated data, as we see here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gd['model_data']['o15ag10.0'].keys())\n",
    "print('\\n')\n",
    "\n",
    "#Overview and bulk data\n",
    "for key in list(gd['model_data']['o15ag10.0'].keys())[0:5]:\n",
    "    print('{} --> {}'.format(key, gd['model_data']['o15ag10.0'][key]))\n",
    "key='kepler_label' #this is a simple short label used by kepler to keep track of the model\n",
    "print('{} --> {}'.format(key, gd['model_data']['o15ag10.0'][key]))\n",
    "    \n",
    "    \n",
    "    \n",
    "#Raw full lightcurve data\n",
    "print('raw_lc_time --> <numpy array of raw lightcurve time in seconds>')\n",
    "print('raw_lc_lum --> <numpy array of raw lightcurve luminosity in erg/s>')\n",
    "print('raw_lc_rad --> <numpy array of raw lightcurve photosphere radius in cm>')\n",
    "\n",
    "#Burst data in which the above lightcurve is broken up into distinct bursts (`nbursts` tells you how many there are)\n",
    "print('burst_times --> <a list of `nburst` numpys arrays containing that burst time, with t=0s being the peak time>')\n",
    "print('burst_lums  --> <a list of `nburst` numpys arrays containing that burst luminosity L(t), with t coming from corresponding burst_times>')\n",
    "print('alc_arr     --> <a list of [time, lum, rad] numpy arrays representing the average of all bursts>')\n",
    "\n",
    "#Detailed profile (ash!) data is available through kepler's dump files:\n",
    "print(gd['model_data']['o15ag10.0']['dump_data'].keys())\n",
    "\n",
    "#More data is available for each dumpfile, but some pickles (like this one) only have initial bulk data (the model's iteration ncyc, index of ash base jblo, path, etc) and will need the full ash data added once brought in from iCER:\n",
    "print(gd['model_data']['o15ag10.0']['dump_data']['gs18#32000'].keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
