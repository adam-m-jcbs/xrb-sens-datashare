#!/usr/bin/env python

#While this repository is being built out, we provide raw data that, as one
#might expect, is a bit messy and requires some dependencies on analysis modules.

#Reduced data is also provided, but this script will aide in the exploration of
#raw data (this data is given as-is, and thus is not guaranteed to be free of numerical noise or
#other issues, which are addressed in our data reduction and analysis pipelines.)

#This script is provided along with modules which enable any researcher
#competent in Python to explore the same full raw data set generated by our
#simulations that we (JINA-CEE/MSU/FRIB) reduce and analyze.

#REQUIREMENTS!:
# While we're working to reduce dependencies, for now you will need to provide:
# - scipy, numpy-quaternion, matplotlib

#---

#Provide analysis, data abstraction, and reduction modules as well as modules
#that understand Kepler's data formats
#NOTE: This is very hacky and brittle. Should be improved in next development iteration.
import sys
import os
import re
from pickle import dump, load
from glob import glob
from os.path import basename, join
from random import sample
from scipy.constants import physical_constants

##Hacky hard-coded variables
#cur_home = '/home/ajacobs'
cur_data_root = '/home/ajacobs/Reporoot/xrb-sens-datashare/raw_pickles'
#cur_model = '4u1820ZJ'
#cur_grid = 'grid_100x'
package_root = '{}/../analysis_packages'.format(cur_data_root)
kepler_package_root = '{}/../kepler_python_packages'.format(cur_data_root)
#os.environ["KEPLER_GRIDS"]  = "{}/{}/{}/grids".format(cur_data_root, cur_model, cur_grid)
#os.environ["KEPLER_MODELS"] = "{}/{}/{}/models".format(cur_data_root, cur_model, cur_grid)
# Kepler (https://2sn.org/kepler/doc/)
#kepler_path = '{}/current_kepler'.format(codebase)
#os.environ["KEPLER_PATH"]  = kepler_path
#os.environ["KEPLER_DATA"]  = "{}/local_data/".format(kepler_path)
# Mongo is used for Kepler visualization/plotting
#mongo_path = '{}/current_kepler/mongo'.format(codebase)
#os.environ["MONGO_PATH"]  = mongo_path
#os.environ["HELPFILE"]    = '{}/help.dat'.format(mongo_path)
#os.environ["MONGOPS"]     = '{}/postscript/'.format(mongo_path)
#os.environ["FONTDAT"]     = '{}/fonts.dat'.format(mongo_path)
#os.environ["FONTNEW"]     = '{}/fonts.vis'.format(mongo_path)

#Hack parts of infrastructure into the python path
#WARNING: ORDER matters due to modules that clober namespaces
#sys.path.insert(0, '{}/kepler-analyser/'.format(package_root))
#sys.path.insert(0, "{}/grid_setup/".format(package_root))
sys.path.insert(0, '{}/python_scripts'.format(kepler_package_root))

#import grid_setup
#from model_analysis import ModelAnalysis
from lcdata import LCData
from kepdata import KepData
from kepdump import KepDump
from isoplot import IsoPlot
from nucplot import IsoPlot as NucPlot
import bdat
import ionmap
from isotope import el2z


#With dependencies provided, reading up to the entire raw data set is as easy as
#manipulating a nested Python dictionary full of performant numpy objects as
#well as self-documenting labels/descriptions.
#
#This function loads and returns the raw data as a Python dictionary.

if __name__ == "__main__":
    #The executed body of the script starts here

    #Below is a reference example of leading in the pickle, doing some checks, and
    #highlighting some of the detailed data available.
    #Load in the raw data
    print('About to open')
    with open('gs1826_10x_grid_data.Nov5.pk', 'rb') as f:
        grid_data = load(f)
   
    gd = grid_data
    #Do a basic check of the data
    #summarize the grid properties
    print("Grid label:       {}".format(gd['grid_label']))
    print("Grid description: {}".format(gd['grid_desc']))
    print("X:      {}".format(gd['x']))
    print("Z(n14): {}".format(gd['z']))
    print("Q_b:    {} MeV / u".format(gd['qb']))
    print("Eddington fraction: {}".format(gd['eddf']))
    print("xi: {}".format(gd['xi']))
    print("Accretion Lum: {} erg / s".format(gd['acc_lum']))
    print("Accretion Rate: {} M_sol / yr".format(gd['acc_rate']))
    print("surface gravity, g: {} cm / s^2".format(gd['gee']))
    print("# of variations (may be off by 1, see source): {}".format(len(gd['vary_list'])-1)) #-1 because we currently put fake variation in first to gen the baseline
    print("# of models: {}".format(len(gd['model_data'])))
    print("")

    #An example of raw radial ash data

    pass
